# -*- coding: utf-8 -*-
"""Predicting_Personal_Loan_Task_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kb42WTb53qd82wFgDBJ_Tv7nHLbm7qjL

**Task 2** Milestone 2
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns 
import sklearn
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import RandomizedSearchCV
import imblearn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

#importing the dataset which is in csv file
data=pd.read_csv('/content/Bank_Personal_Loan.csv')
data.head()

data.info()

#finding the sum of null values in each column
data.isnull().sum()

data['ID'] = data['ID'].fillna(data['ID'].mode()[0])

data['Age'] = data['Age'].fillna(data['Age'].mode()[0])

data['Experience'] = data['Experience'].fillna(data['Experience'].mode()[0])

#data['Income']=data['Income'].str.replace('+','')

data['ZIP Code'] = data['ZIP Code'].fillna(data['ZIP Code'].mode()[0])
data['Family'] = data['Family'].fillna(data['Family'].mode()[0])
data['CCAvg'] = data['CCAvg'].fillna(data['CCAvg'].mode()[0])
data['Education'] = data['Education'].fillna(data['Education'].mode()[0])
data['Mortgage'] = data['Mortgage'].fillna(data['Mortgage'].mode()[0])
data['Personal Loan'] = data['Personal Loan'].fillna(data['Personal Loan'].mode()[0])
data['Securities Account'] = data['Securities Account'].fillna(data['Securities Account'].mode()[0])
data['CD Account'] = data['CD Account'].fillna(data['CD Account'].mode()[0])
data['Online'] = data['Online'].fillna(data['Online'].mode()[0])
data['CreditCard'] = data['CreditCard'].fillna(data['CreditCard'].mode()[0])

data['ID']=data['ID'].astype('int64')
data['Age']=data['Age'].astype('int64')
data['Experience']=data['Experience'].astype('int64')
data['ZIP Code']=data['ZIP Code'].astype('int64')
data['Family']=data['Family'].astype('int64')
data['Education']=data['Education'].astype('int64')
data['Mortgage']=data['Mortgage'].astype('int64')
data['Personal Loan']=data['Personal Loan'].astype('int64')
data['Securities Account']=data['Securities Account'].astype('int64')
data['CD Account']=data['CD Account'].astype('int64')
data['Online']=data['Online'].astype('int64')
data['CreditCard']=data['CreditCard'].astype('int64')

#Balancine dataset by using smote
from imblearn.combine import SMOTETomek

smote = SMOTETomek(0.90)

#dividing the dataset into dependent nd independent y and x respectively
y=data['Personal Loan']
x=data.drop(columns=['Personal Loan'],axis=1)

#ceating a new x and y variables for the balanced set
x_bal,y_bal=smote.fit_resample(x,y)

#printing the values of y before balancing the data and after
print(y.value_counts())
print(y_bal.value_counts())

"""**Task 3** Milestone 3"""

data.describe()

#plotting the using distplot
plt.figure(figsize=(12,5))
plt.subplot(121)
plt.displot(data['Income'])
plt.subplot(122)
sns.displot(data['CD Account'])
plt.show()

#plotting the count plot
plt.figure(figsize=(18,4))
plt.subplot(1,4,1)
sns.countplot(data['Experience'])
plt.subplot(1,4,3)
sns.countplot(data['Education'])
plt.show()

#visualising two columns against each other
plt.figure(figure=(20,5))
plt.subplot(131)
sns.countplot(data['ID'], hue=data['Age'])
plt.subplot(132)
sns.countplot(data['Experience'], hue=data['Education'])
plt.subplot(133)
sns.countplot(data['Income'], hue=data['Personal Loan'])

#visulized based gender and income what would be the application status
sns.swarmplot(data['Age'],data['Income'], hue = data['CD Account'])

#perfroming feature scaling iperation using standard scaller on x part of the dataset because
#there different type of values in the columns
from imblearn.combine import SMOTETomek
smote = SMOTETomek(0.90)
x_bal,y_bal = smote.fit_resample(x,y)
sc=StandardScaler()
x_bal=sc.fit_transform(x_bal)
x_bal=pd.DataFrame(x.bal,columns=names)

#splitting the dataset in train and test on balanced datasew
x_train, x_test, y_train, y_test = train_test_split(x_bal, y_bal, test_size=0.33, random_state=42)

"""**Task 4** Milestone 4"""

def decisionTree(x_train,x_test,y_train,y_test):
    dt=DecisionTreeClassifier()
    dt.fix(x_train,y_train)
    yPred=dt.predict(x_test)
    print('***DecisionTreeClassifier***')
    print('Confusion matrix')
    print(confusion_matrix(y_test,yPred))
    print('Classification report')
    print(classification_report(y_test,yPred))

def randomForest(x_train,x_test,y_train,y_test):
    rf=RandomForestClassifier()
    rf.fit(x_train,y_train)
    yPred=rf.predict(x_test)
    print('***RandomForestClassifier***')
    print('Confusion matrix')
    print(confusion_matrix(y_test,yPred))
    print('Classification report')
    print(classification_report(y_test,yPred))

def KNN(x_train,x_test,y_train,y_test):
    knn=KNeighborsClassifier()
    knn.fit(x_train,y_train)
    yPred=knn.predict(x_test)
    print('***KNeighborsClassifier***')
    print('Confusion matrix')
    print(confusion_matrix(y_test,yPred))
    print('Classification report')
    print(classification_report(y_test,yPred))

def xgboost(x_train,x_test,y_train,y_test):
    xg=GradientBoostingClassifier()
    xg.fit(x_train,y_train)
    yPred=xg.predict(x_test)
    print('***GradientBoostingClassifier***')
    print('Confusion matrix')
    print(confusion_matrix(y_test,yPred))
    print('Classification report')
    print(classification_report(y_test,yPred))

#ANN
#importing the keras libraries and packages
import tensorflow
from tensorflow.keras.models import sequential
from tensorflow.keras.layers import Dense

#Initialising the ANN
classifier = sequential()

#Adding the input layer and the first hidden layer
classifier.add(Dense(units=100,activation='relu',input_dim=11))

#Adding the second hidden layer
classifier.add(Dense(units=50,activation='relu'))

#Adding the output layer
classifier.add(Dense(units=1,activation='sigmoid'))

#Compiling the ANN
classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

#Fitting the ANN to the Training set
model_history=classifier.fit(x.train,y_train,batch_size=100,validation_split=0.2,epochs=100)

#Gender Married Dependents Education Self Employed Application CoapplicationIncome Loan_AccountTera
dtr.predict([[1,1,0,4276,240,0,1]])

rfr.predict([[1,1,0,1,1,4276,1542,145,0,1]])

knn.predict([[1,1,0,1,1,4276,1542,145,0,1]])

xgb.predict([[1,1,0,1,1,4276,1542,145,0,1]])

classifier.save("loan.h5")

#predicting the Test set results
y_pred=classifier.predict(x_test)

y_pred

y_pred=(y_pred>0.5)
y_pred

def predict_exit(sample_value):
sample_value = np.array(sample_value)
sample_value=sample_value.reshape(1, -1)
sample_value=sc.transform(sample_value)
return classifier.predict(sample_value)

sample_value=[[1,1, 0, 1, 4276, 1542,145,240,0,1]]
if predict_exit(sample_value)>0.5:
print('prediction: High chance of Loan Approval!')
else:
print('prediction:low chance Loan Approval.')

sample_value=[[1,0, 1, 1, 1, 45, 14,45,240, 1,1]]
if predict_exit(sample_value)>0.5:
print('prediction: High chance of Loan Approval!')
else:
print('prediction:low chance Loan Approval.')

"""***Task 5*** Milestone 5"""

def compareModel(x_train,x_test,y_train,y_test):
decisionTree(x_train,x_test,y_train,y_test)
print('-'*100)
RandomForest(x_train,x_test,y_train,y_test)
print('-'*100)
XGB(x_train,x_test,y_train,y_test)
print('-'*100)
KNN(x_train,x_test,y_train,y_test)
print('-'*100)

compareModel(X_train,X_test,y_train,y_test)

yPred = classfier.predict(X_test)
print(accuracy_score(y_pred,y_test))
print("ANN Model")
print("Confusion_Matrix")
print(confusion _matrix(y_test,y_pred))
print("Classification Report")
print(classification_report(y_test,y_pred))

from sklearn.model_selection import cros_val_score

# Randam forest  model is selected
rf = RandomForestClassifier()
rf.fit(x_train,y_train)
ypred = rf.predict(x_test)

f1_score(ypred,y_test,average='weighted')

cv = cross_val_score(rf,x,y,cv=5)

np.mean(cv)

"""**Task 6** Milestone 6"""

pickle.dump(model,open('rdf.pkl','wb'))

from flask import Flask , render_templete, request
import numpy as np
import pickle

app = Flask(_name_)
model = pickle.load(open(r'rdf.pkl','rb'))
scale = pickle.load(open(r'scole1.pkl','rb'))

input_feature=[int(x) for x in request.form.values() ]

input_feature=[np.array(input_feature)]
print(input_features)
names = ['Gender','Married','Depends','Education','ApplicantIncome',CoapplicatntIncome','LoanAmount','Loan_Amount_Term','Crdit_history','Property_Area']
data = pandas.DataFrame(input_features,columns=names
print(data)

prediction = model1.predict(data)
print(prediction)
prediction=int(prediction)
print(type(prediction))

if (prediction == 0):
return render_template("output.html",result="Loan Will not be Approved")
else:
return render_template("output.html",result="Loan Will not be Approved")

if __name__=="__main__":

port=int(os.environ.get('PORT',5000))
app.run(debug=false)

